{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a001658c",
   "metadata": {},
   "source": [
    "# Load New Dataset - Test Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "145dbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import lesco as lsc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b64e336",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bfff327f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336 video images detected\n"
     ]
    }
   ],
   "source": [
    "root = r'C:\\Users\\XPC\\Desktop\\single-frame'\n",
    "\n",
    "classes_ = []\n",
    "files_ = []\n",
    "\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    for name in files:\n",
    "        file_path = path + \"\\\\\" + name\n",
    "        img_class = name.split('_')[1].split('.')[0]\n",
    "        files_.append(file_path)\n",
    "        classes_.append(img_class)\n",
    "        \n",
    "print(len(files_), \"video images detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a333883",
   "metadata": {},
   "source": [
    "## Augment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fc971118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\022965aa-2fa0-4bbf-a2b3-bcfd38aca605_desmayar.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\064dc251-0707-482d-9f15-1e283fdad11c_calle.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\0f49fb95-4f54-4402-8bdd-39b43625e4b8_fuego.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\1c5306b0-8b4f-48b5-aaec-2ca2385996c9_cocina.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\271cfe1d-ed51-4a34-9def-b8e4b81adc37_basura.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\27bd62e0-bfb1-4e5f-9393-e5b174b58dbc_casa.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\285e0319-1a31-4000-afa6-910e71c201c7_casa.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\2f798c09-5e73-49ea-9872-98e6a22fcd13_yo.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\31a31d50-bd8b-465e-abed-edc0a1beeee5_fuego.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\35046a2f-2b54-4462-97ca-6e98be8ae3d1_tener.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\35bc935d-4b4f-45e2-9403-cc155a2158f3_ebrio.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\36e059a7-327a-4620-9b46-a1d5277cd361_muerto.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\3d359cd4-1ff7-4b10-bf9a-188b1df57a1f_vecino.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\4648bbef-8c79-4c89-8850-e5ad714106ff_calle.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\49ec6207-eec2-4ba5-8ee4-cef32b0937ff_hijo.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\4ba77ff0-19ac-47ef-8248-2c035e5bb723_hijo.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\4ef06059-e82f-49fd-abed-d3acfcc1fa49_nacerbebe.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\5175d9e9-8300-4118-b269-1cf2b833348c_yo.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\5319219f-315c-49d3-a6cd-3cb602df32f3_hijo.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\55f682dc-0fc1-434d-8df8-3e69fd0eaa16_tener.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\5a670413-9e13-4f6b-9af1-c127835e26e4_vomitar.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\5faa35dd-e551-4054-a787-3e88965c6624_calle.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\6335d578-0fee-47c4-b36d-54ac956a6955_esposo.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\637ea6e5-bc6f-4271-9ac0-06fd7ce77f43_nopermiso.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\655041bc-b1b2-4824-948e-6bb88dc2c360_hermana.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\7031a2d7-266b-4b5a-b784-23a70119ee4f_hijo.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\72d2ffb0-b37a-4367-a846-068d6d78248c_nacerbebe.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\75967e33-dad7-489c-b611-d1ec3fb075bf_madre.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\7cbcb1e9-aeb2-457b-b75e-a4a595718ab6_padre.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\7cbfe1e6-bb69-4d45-afb0-0fb5d8a7a747_nopermiso.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\81395757-33f3-4b7e-9bf1-9ebf275dbb23_calle.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\8237d356-320d-4266-98de-35c1cca86bed_fuego.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\829d0889-e797-4225-9474-8f3138a4cf49_nopermiso.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\8319fb35-a980-49cd-9ec0-499de11f4df1_llavecarro.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\83e6a99c-af94-4ca8-8fcd-2fcc87e8507f_vecino.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\879797a5-1994-4be8-981e-8e947a37f2c5_yo.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\8859a4d8-7a4e-477a-8906-bf8b35974ec4_llavecarro.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\8aedf4cb-3856-453d-b651-81da6ec900a9_muerto.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\91038cba-7c22-482d-9e31-bf1fc72f9d2a_basura.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\929dd494-ed70-4203-b677-eafa1a584285_carro.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\992c675d-f73f-4459-a204-473e4924ebf3_pistola.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\9a17cfda-69b0-4ee4-abc7-66019834544e_cocina.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\9aaa193a-01a1-4284-bd78-c34bd33af690_fuego.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\a900e323-08dc-4ee8-b5c3-116ced39033e_hijo.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\af729a29-1a02-413a-af62-c44c91fbdbed_madre.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\b639d3fb-6b46-4353-81ae-e374054665a6_fuego.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\b98d3c64-6bf5-4228-b62b-22f017b4ea8a_agredir.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\ba4bb835-054a-4d7a-8328-3c4f1b1e261d_pistola.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\bb068097-83aa-46fd-b618-cb829a674554_padre.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\bc315673-9dd1-43dc-a2f2-6c216b50a2cc_muerto.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\c6f2a8f7-5434-41f9-9f38-32116664668b_desmayar.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\cb09ea86-5337-4332-8772-ee51864fed00_desmayar.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\cbe33ab6-c934-4424-af18-ab24acef4e78_padre.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\d627720d-64f2-4110-b2db-3f8126949ff6_fosforo.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\d870237a-4d71-42ae-ac5c-ef465d0c587d_personaacostada.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\d8ea5f74-0d2b-48d4-8153-207fc30466e5_hijo.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\de669070-a3fa-439e-8911-3a29d5b67ca1_fuego.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\e3cab081-19cb-4539-99a2-bd6b8449e357_muerto.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\e77ba8e9-09ad-4c3e-8788-0024c944d03f_esposo.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\e993c93b-d3ae-4f0e-9f9c-8893cdba0636_fuego.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\e9e95d62-37ed-47dc-b83f-460c93f6929e_inconsciente.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\ef5913da-109f-4dc6-b4cc-edd46299461f_vomitar.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\f0e78444-5d20-4146-811f-2eaaf5dec981_fuego.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\f499a41c-3fc4-424a-b176-ff2dcaf6738d_agredir.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\f7ae0bb9-705e-4ddd-a671-c25a8c09f2cf_vomitar.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\f7fbfef4-b88d-481b-9c8c-27dc2d6b9bd9_llavecarro.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\f8553b35-dbd2-42e6-a7b1-d69f21cbddd0_calle.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\fca3342c-1215-4306-8480-ba03b0bcce4c_tio.png\n",
      "No hands at C:\\Users\\XPC\\Desktop\\single-frame\\fe7aac21-1a81-41bf-927c-0f909999e66f_hermana.png\n",
      "Total samples created 1636 1636\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "count = 0\n",
    "\n",
    "for url, class_ in zip(files_, classes_):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        # code from notebook 1\n",
    "        img = cv.imread(url)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        v1 = lsc.process_image(img, False, False, 0)\n",
    "        v2 = lsc.process_image(img, True, False, 0)\n",
    "        v3 = lsc.process_image(img, False, True, 5)\n",
    "        v4 = lsc.process_image(img, False, True, -5)\n",
    "        v5 = lsc.process_image(img, True, True, 5)\n",
    "        v6 = lsc.process_image(img, True, True, -5)\n",
    "\n",
    "        if (v1 is None):\n",
    "            print(\"No hands at\", url)\n",
    "\n",
    "        if(v1 is not None):\n",
    "            X.append(v1)\n",
    "            y.append(class_)\n",
    "\n",
    "        if(v2 is not None):\n",
    "            X.append(v2)\n",
    "            y.append(class_)\n",
    "\n",
    "        if(v3 is not None):\n",
    "            X.append(v3)\n",
    "            y.append(class_)\n",
    "\n",
    "        if(v4 is not None):\n",
    "            X.append(v4)\n",
    "            y.append(class_)\n",
    "\n",
    "        if(v5 is not None):\n",
    "            X.append(v5)\n",
    "            y.append(class_)\n",
    "\n",
    "        if(v6 is not None):\n",
    "            X.append(v6)\n",
    "            y.append(class_)\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "        #if (count % 10 == 0):\n",
    "        #    clear_output(wait=True)\n",
    "    except Exception as e:\n",
    "        print(\"error\",str(e))\n",
    "    \n",
    "print(\"Total samples created\", len(X), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8b5d24",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fca2bece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1308\n",
      "Training 328\n"
     ]
    }
   ],
   "source": [
    "# test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=43)\n",
    "\n",
    "print(\"Training\", len(X_train))\n",
    "print(\"Training\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6d067a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manhattan(train_data, test_item):\n",
    "    similarity = []\n",
    "    for data in train_data:\n",
    "        s = 1 - np.abs(np.array(data) - np.array(test_item)).sum()\n",
    "        similarity.append(s)\n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "        \"y_train\" : y_train,\n",
    "        \"similarity\" : similarity\n",
    "    })\n",
    "    \n",
    "    df = df.sort_values(by=['similarity'], ascending=False)\n",
    "    \n",
    "    return df.iloc[0][\"y_train\"]  # returns most similar class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f130590b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan Normal Fn Test Set Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "total = len(X_test)\n",
    "count = 0\n",
    "\n",
    "for test, label in zip(X_test, y_test):\n",
    "    y_pred = get_manhattan(X_train, test)\n",
    "    \n",
    "    if (y_pred == label):\n",
    "        count = count + 1\n",
    "\n",
    "print(\"Manhattan Normal Fn Test Set Accuracy:\", round(count/total,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5933ff30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.81, 0.8, 0.79, 0.76, 0.78]\n",
      "Manhattan Cross Validation 0.788\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(0,5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "    total = len(X_test)\n",
    "    count = 0\n",
    "    for test, label in zip(X_test, y_test):\n",
    "        y_pred = get_manhattan(X_train, test)\n",
    "        if (y_pred == label):\n",
    "            count = count + 1\n",
    "    scores.append(round(count/total,2))\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Manhattan Cross Validation\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660a78fc",
   "metadata": {},
   "source": [
    "# Video Sentence Prediction\n",
    "\n",
    "Every frame of the video is classified. Then if there are trends of common words, they will be used as the idenfied token words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f143521d",
   "metadata": {},
   "source": [
    "## Load Lesco Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e58e1b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 emergency videos detected\n"
     ]
    }
   ],
   "source": [
    "root = r'C:\\Users\\XPC\\Desktop\\LESCO-oraciones'\n",
    "\n",
    "files_ = []\n",
    "\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    for name in files:\n",
    "        class_name = os.path.basename(path)\n",
    "        file_path = path + '\\\\' + name\n",
    "        files_.append(file_path)\n",
    "        \n",
    "print(len(files_),\"emergency videos detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a6eb82fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XPC\\Desktop\\LESCO-oraciones\\bomberos_Estan quemando basura.mp4\n"
     ]
    }
   ],
   "source": [
    "# they are burning trash\n",
    "video_url = files_[0]\n",
    "print(video_url)\n",
    "\n",
    "cap = cv.VideoCapture(video_url)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv.resize(frame, (480,300), interpolation = cv.INTER_AREA)            \n",
    "    cv.imshow('frame', frame)\n",
    "\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52dafcd",
   "metadata": {},
   "source": [
    "## Video Frame Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b6699765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_words(files_, index):\n",
    "    i = 0\n",
    "    i_succ = 0\n",
    "    identified_classes = []\n",
    "\n",
    "    video_url = files_[index]\n",
    "    print(video_url)\n",
    "\n",
    "    cap = cv.VideoCapture(video_url)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        # if frame is read correctly ret is True\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv.resize(frame, (480,300), interpolation = cv.INTER_AREA)            \n",
    "\n",
    "        try:\n",
    "            # get hands metadata\n",
    "            frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "            lesco_array = lsc.process_image(frame, False, False, 0)\n",
    "\n",
    "            if (type(lesco_array) != type(None)):\n",
    "                y_pred = get_manhattan(X_train, lesco_array)\n",
    "                identified_classes.append(y_pred)\n",
    "                i_succ += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    print(\"Total Frames Processed\", i)\n",
    "    print(\"Total Classifications\", i_succ)\n",
    "    return identified_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7c5d5d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(identified_classes, threshold):\n",
    "    ln = len(identified_classes)\n",
    "    i = 0\n",
    "\n",
    "    while i < ln:\n",
    "        word = identified_classes[i]\n",
    "        word_count = 1\n",
    "\n",
    "        z = i\n",
    "        for j in range(z, ln):\n",
    "            if (word == identified_classes[j]):\n",
    "                word_count += 1\n",
    "            else:\n",
    "                i = i + word_count\n",
    "                break\n",
    "\n",
    "        if (word_count > threshold):\n",
    "            print(word, word_count, i, i + word_count, ln) \n",
    "            \n",
    "        if (i + word_count > ln):\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a75d48b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XPC\\Desktop\\LESCO-oraciones\\bomberos_Estan quemando basura.mp4\n",
      "Total Frames Processed 323\n",
      "Total Classifications 265\n",
      " \n",
      "ellos 26 46 72 265\n",
      "fosforo 15 93 108 265\n",
      "basura 28 258 286 265\n"
     ]
    }
   ],
   "source": [
    "# Estan quemando basura\n",
    "\n",
    "identified_classes = get_video_words(files_, 0)  \n",
    "print(\" \")\n",
    "predict_sentence(identified_classes, 14) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae87afcd",
   "metadata": {},
   "source": [
    "## Predict Second Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5b62ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XPC\\Desktop\\LESCO-oraciones\\bomberos_Están cortando árboles sin permiso.mp4\n",
      "Total Frames Processed 245\n",
      "Total Classifications 100\n",
      " \n",
      "carro 5 61 66 100\n",
      "nopermiso 29 72 101 100\n"
     ]
    }
   ],
   "source": [
    "# Están cortando árboles sin permiso\n",
    "\n",
    "identified_classes = get_video_words(files_, 1)  \n",
    "print(\" \")\n",
    "predict_sentence(identified_classes, 4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094b48df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
